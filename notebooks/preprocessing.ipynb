{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "from lazypredict import Supervised\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tune_sklearn import TuneGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "pd.set_option(\"display.width\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>qty_tilde_url</th>\n",
       "      <th>qty_comma_url</th>\n",
       "      <th>qty_plus_url</th>\n",
       "      <th>qty_asterisk_url</th>\n",
       "      <th>qty_hashtag_url</th>\n",
       "      <th>qty_dollar_url</th>\n",
       "      <th>qty_percent_url</th>\n",
       "      <th>qty_tld_url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>qty_dot_domain</th>\n",
       "      <th>qty_hyphen_domain</th>\n",
       "      <th>qty_underline_domain</th>\n",
       "      <th>qty_slash_domain</th>\n",
       "      <th>qty_questionmark_domain</th>\n",
       "      <th>qty_equal_domain</th>\n",
       "      <th>qty_at_domain</th>\n",
       "      <th>qty_and_domain</th>\n",
       "      <th>qty_exclamation_domain</th>\n",
       "      <th>qty_space_domain</th>\n",
       "      <th>qty_tilde_domain</th>\n",
       "      <th>qty_comma_domain</th>\n",
       "      <th>qty_plus_domain</th>\n",
       "      <th>qty_asterisk_domain</th>\n",
       "      <th>qty_hashtag_domain</th>\n",
       "      <th>qty_dollar_domain</th>\n",
       "      <th>qty_percent_domain</th>\n",
       "      <th>qty_vowels_domain</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_in_ip</th>\n",
       "      <th>server_client_domain</th>\n",
       "      <th>qty_dot_directory</th>\n",
       "      <th>qty_hyphen_directory</th>\n",
       "      <th>qty_underline_directory</th>\n",
       "      <th>qty_slash_directory</th>\n",
       "      <th>qty_questionmark_directory</th>\n",
       "      <th>qty_equal_directory</th>\n",
       "      <th>qty_at_directory</th>\n",
       "      <th>qty_and_directory</th>\n",
       "      <th>qty_exclamation_directory</th>\n",
       "      <th>qty_space_directory</th>\n",
       "      <th>qty_tilde_directory</th>\n",
       "      <th>qty_comma_directory</th>\n",
       "      <th>qty_plus_directory</th>\n",
       "      <th>qty_asterisk_directory</th>\n",
       "      <th>qty_hashtag_directory</th>\n",
       "      <th>qty_dollar_directory</th>\n",
       "      <th>qty_percent_directory</th>\n",
       "      <th>directory_length</th>\n",
       "      <th>qty_dot_file</th>\n",
       "      <th>qty_hyphen_file</th>\n",
       "      <th>qty_underline_file</th>\n",
       "      <th>qty_slash_file</th>\n",
       "      <th>qty_questionmark_file</th>\n",
       "      <th>qty_equal_file</th>\n",
       "      <th>qty_at_file</th>\n",
       "      <th>qty_and_file</th>\n",
       "      <th>qty_exclamation_file</th>\n",
       "      <th>qty_space_file</th>\n",
       "      <th>qty_tilde_file</th>\n",
       "      <th>qty_comma_file</th>\n",
       "      <th>qty_plus_file</th>\n",
       "      <th>qty_asterisk_file</th>\n",
       "      <th>qty_hashtag_file</th>\n",
       "      <th>qty_dollar_file</th>\n",
       "      <th>qty_percent_file</th>\n",
       "      <th>file_length</th>\n",
       "      <th>qty_dot_params</th>\n",
       "      <th>qty_hyphen_params</th>\n",
       "      <th>qty_underline_params</th>\n",
       "      <th>qty_slash_params</th>\n",
       "      <th>qty_questionmark_params</th>\n",
       "      <th>qty_equal_params</th>\n",
       "      <th>qty_at_params</th>\n",
       "      <th>qty_and_params</th>\n",
       "      <th>qty_exclamation_params</th>\n",
       "      <th>qty_space_params</th>\n",
       "      <th>qty_tilde_params</th>\n",
       "      <th>qty_comma_params</th>\n",
       "      <th>qty_plus_params</th>\n",
       "      <th>qty_asterisk_params</th>\n",
       "      <th>qty_hashtag_params</th>\n",
       "      <th>qty_dollar_params</th>\n",
       "      <th>qty_percent_params</th>\n",
       "      <th>params_length</th>\n",
       "      <th>tld_present_params</th>\n",
       "      <th>qty_params</th>\n",
       "      <th>email_in_url</th>\n",
       "      <th>time_response</th>\n",
       "      <th>domain_spf</th>\n",
       "      <th>asn_ip</th>\n",
       "      <th>time_domain_activation</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246</td>\n",
       "      <td>1</td>\n",
       "      <td>13335</td>\n",
       "      <td>1640</td>\n",
       "      <td>551</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249</td>\n",
       "      <td>1</td>\n",
       "      <td>14618</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0</td>\n",
       "      <td>13335</td>\n",
       "      <td>5355</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112</td>\n",
       "      <td>1</td>\n",
       "      <td>36352</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>7865</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  qty_exclamation_url  qty_space_url  qty_tilde_url  qty_comma_url  qty_plus_url  qty_asterisk_url  qty_hashtag_url  qty_dollar_url  qty_percent_url  qty_tld_url  length_url  qty_dot_domain  qty_hyphen_domain  qty_underline_domain  qty_slash_domain  qty_questionmark_domain  qty_equal_domain  qty_at_domain  qty_and_domain  qty_exclamation_domain  qty_space_domain  \\\n",
       "0            1               0                  0              1                     0              0           0            0                    0              0              0              0             0                 0                0               0                0            1          13               1                  0                     0                 0                        0                 0              0               0                       0                 0   \n",
       "1            2               5                  4              2                     0              0           0            0                    0              0              0              0             0                 0                0               0                0            1         329               2                  0                     0                 0                        0                 0              0               0                       0                 0   \n",
       "2            2               0                  0              0                     0              0           0            0                    0              0              0              0             0                 0                0               0                0            1          24               2                  0                     0                 0                        0                 0              0               0                       0                 0   \n",
       "3            1               1                  0              2                     0              0           0            0                    0              0              0              0             0                 0                0               0                0            1          23               1                  1                     0                 0                        0                 0              0               0                       0                 0   \n",
       "4            2               1                  0              0                     0              0           0            0                    0              0              0              0             0                 0                0               0                0            1          23               2                  1                     0                 0                        0                 0              0               0                       0                 0   \n",
       "\n",
       "   qty_tilde_domain  qty_comma_domain  qty_plus_domain  qty_asterisk_domain  qty_hashtag_domain  qty_dollar_domain  qty_percent_domain  qty_vowels_domain  domain_length  domain_in_ip  server_client_domain  qty_dot_directory  qty_hyphen_directory  qty_underline_directory  qty_slash_directory  qty_questionmark_directory  qty_equal_directory  qty_at_directory  qty_and_directory  qty_exclamation_directory  qty_space_directory  qty_tilde_directory  qty_comma_directory  qty_plus_directory  \\\n",
       "0                 0                 0                0                    0                   0                  0                   0                  1              7             0                     0                  0                     0                        0                    1                           0                    0                 0                  0                          0                    0                    0                    0                   0   \n",
       "1                 0                 0                0                    0                   0                  0                   0                  8             24             0                     0                  0                     5                        4                    2                           0                    0                 0                  0                          0                    0                    0                    0                   0   \n",
       "2                 0                 0                0                    0                   0                  0                   0                  7             24             0                     0                 -1                    -1                       -1                   -1                          -1                   -1                -1                 -1                         -1                   -1                   -1                   -1                  -1   \n",
       "3                 0                 0                0                    0                   0                  0                   0                  5             17             0                     0                  0                     0                        0                    2                           0                    0                 0                  0                          0                    0                    0                    0                   0   \n",
       "4                 0                 0                0                    0                   0                  0                   0                  6             23             0                     0                 -1                    -1                       -1                   -1                          -1                   -1                -1                 -1                         -1                   -1                   -1                   -1                  -1   \n",
       "\n",
       "   qty_asterisk_directory  qty_hashtag_directory  qty_dollar_directory  qty_percent_directory  directory_length  qty_dot_file  qty_hyphen_file  qty_underline_file  qty_slash_file  qty_questionmark_file  qty_equal_file  qty_at_file  qty_and_file  qty_exclamation_file  qty_space_file  qty_tilde_file  qty_comma_file  qty_plus_file  qty_asterisk_file  qty_hashtag_file  qty_dollar_file  qty_percent_file  file_length  qty_dot_params  qty_hyphen_params  qty_underline_params  qty_slash_params  \\\n",
       "0                       0                      0                     0                      0                 6             0                0                   0               0                      0               0            0             0                     0               0               0               0              0                  0                 0                0                 0            5              -1                 -1                    -1                -1   \n",
       "1                       0                      0                     0                      0               305             0                5                   4               0                      0               0            0             0                     0               0               0               0              0                  0                 0                0                 0          302              -1                 -1                    -1                -1   \n",
       "2                      -1                     -1                    -1                     -1                -1            -1               -1                  -1              -1                     -1              -1           -1            -1                    -1              -1              -1              -1             -1                 -1                -1               -1                -1           -1              -1                 -1                    -1                -1   \n",
       "3                       0                      0                     0                      0                 6             0                0                   0               0                      0               0            0             0                     0               0               0               0              0                  0                 0                0                 0            0              -1                 -1                    -1                -1   \n",
       "4                      -1                     -1                    -1                     -1                -1            -1               -1                  -1              -1                     -1              -1           -1            -1                    -1              -1              -1              -1             -1                 -1                -1               -1                -1           -1              -1                 -1                    -1                -1   \n",
       "\n",
       "   qty_questionmark_params  qty_equal_params  qty_at_params  qty_and_params  qty_exclamation_params  qty_space_params  qty_tilde_params  qty_comma_params  qty_plus_params  qty_asterisk_params  qty_hashtag_params  qty_dollar_params  qty_percent_params  params_length  tld_present_params  qty_params  email_in_url  time_response  domain_spf  asn_ip  time_domain_activation  time_domain_expiration  qty_ip_resolved  qty_nameservers  qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0                       -1                -1             -1              -1                      -1                -1                -1                -1               -1                   -1                  -1                 -1                  -1             -1                  -1          -1             0          0.246           1   13335                    1640                     551                2                2               5           292                    0             -1   \n",
       "1                       -1                -1             -1              -1                      -1                -1                -1                -1               -1                   -1                  -1                 -1                  -1             -1                  -1          -1             0          0.249           1   14618                      -1                      -1                2                4               2            52                    0              1   \n",
       "2                       -1                -1             -1              -1                      -1                -1                -1                -1               -1                   -1                  -1                 -1                  -1             -1                  -1          -1             0          0.529           0   13335                    5355                     123                2                2               0           298                    1              1   \n",
       "3                       -1                -1             -1              -1                      -1                -1                -1                -1               -1                   -1                  -1                 -1                  -1             -1                  -1          -1             0          0.112           1   36352                      -1                      -1                1                2               5          1792                    0              0   \n",
       "4                       -1                -1             -1              -1                      -1                -1                -1                -1               -1                   -1                  -1                 -1                  -1             -1                  -1          -1             0          0.172           0      -1                    7865                    1631                1                2               1           299                    1              1   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"../data/dataset_cybersecurity_michelle.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129698 entries, 0 to 129697\n",
      "Columns: 112 entries, qty_dot_url to phishing\n",
      "dtypes: float64(1), int64(111)\n",
      "memory usage: 110.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>qty_tilde_url</th>\n",
       "      <th>qty_comma_url</th>\n",
       "      <th>qty_plus_url</th>\n",
       "      <th>qty_asterisk_url</th>\n",
       "      <th>qty_hashtag_url</th>\n",
       "      <th>qty_dollar_url</th>\n",
       "      <th>qty_percent_url</th>\n",
       "      <th>qty_tld_url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>qty_dot_domain</th>\n",
       "      <th>qty_hyphen_domain</th>\n",
       "      <th>qty_underline_domain</th>\n",
       "      <th>qty_slash_domain</th>\n",
       "      <th>qty_questionmark_domain</th>\n",
       "      <th>qty_equal_domain</th>\n",
       "      <th>qty_at_domain</th>\n",
       "      <th>qty_and_domain</th>\n",
       "      <th>qty_exclamation_domain</th>\n",
       "      <th>qty_space_domain</th>\n",
       "      <th>qty_tilde_domain</th>\n",
       "      <th>qty_comma_domain</th>\n",
       "      <th>qty_plus_domain</th>\n",
       "      <th>qty_asterisk_domain</th>\n",
       "      <th>qty_hashtag_domain</th>\n",
       "      <th>qty_dollar_domain</th>\n",
       "      <th>qty_percent_domain</th>\n",
       "      <th>qty_vowels_domain</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_in_ip</th>\n",
       "      <th>server_client_domain</th>\n",
       "      <th>qty_dot_directory</th>\n",
       "      <th>qty_hyphen_directory</th>\n",
       "      <th>qty_underline_directory</th>\n",
       "      <th>qty_slash_directory</th>\n",
       "      <th>qty_questionmark_directory</th>\n",
       "      <th>qty_equal_directory</th>\n",
       "      <th>qty_at_directory</th>\n",
       "      <th>qty_and_directory</th>\n",
       "      <th>qty_exclamation_directory</th>\n",
       "      <th>qty_space_directory</th>\n",
       "      <th>qty_tilde_directory</th>\n",
       "      <th>qty_comma_directory</th>\n",
       "      <th>qty_plus_directory</th>\n",
       "      <th>qty_asterisk_directory</th>\n",
       "      <th>qty_hashtag_directory</th>\n",
       "      <th>qty_dollar_directory</th>\n",
       "      <th>qty_percent_directory</th>\n",
       "      <th>directory_length</th>\n",
       "      <th>qty_dot_file</th>\n",
       "      <th>qty_hyphen_file</th>\n",
       "      <th>qty_underline_file</th>\n",
       "      <th>qty_slash_file</th>\n",
       "      <th>qty_questionmark_file</th>\n",
       "      <th>qty_equal_file</th>\n",
       "      <th>qty_at_file</th>\n",
       "      <th>qty_and_file</th>\n",
       "      <th>qty_exclamation_file</th>\n",
       "      <th>qty_space_file</th>\n",
       "      <th>qty_tilde_file</th>\n",
       "      <th>qty_comma_file</th>\n",
       "      <th>qty_plus_file</th>\n",
       "      <th>qty_asterisk_file</th>\n",
       "      <th>qty_hashtag_file</th>\n",
       "      <th>qty_dollar_file</th>\n",
       "      <th>qty_percent_file</th>\n",
       "      <th>file_length</th>\n",
       "      <th>qty_dot_params</th>\n",
       "      <th>qty_hyphen_params</th>\n",
       "      <th>qty_underline_params</th>\n",
       "      <th>qty_slash_params</th>\n",
       "      <th>qty_questionmark_params</th>\n",
       "      <th>qty_equal_params</th>\n",
       "      <th>qty_at_params</th>\n",
       "      <th>qty_and_params</th>\n",
       "      <th>qty_exclamation_params</th>\n",
       "      <th>qty_space_params</th>\n",
       "      <th>qty_tilde_params</th>\n",
       "      <th>qty_comma_params</th>\n",
       "      <th>qty_plus_params</th>\n",
       "      <th>qty_asterisk_params</th>\n",
       "      <th>qty_hashtag_params</th>\n",
       "      <th>qty_dollar_params</th>\n",
       "      <th>qty_percent_params</th>\n",
       "      <th>params_length</th>\n",
       "      <th>tld_present_params</th>\n",
       "      <th>qty_params</th>\n",
       "      <th>email_in_url</th>\n",
       "      <th>time_response</th>\n",
       "      <th>domain_spf</th>\n",
       "      <th>asn_ip</th>\n",
       "      <th>time_domain_activation</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.221</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.132</td>\n",
       "      <td>1.490</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.124</td>\n",
       "      <td>1.054</td>\n",
       "      <td>39.098</td>\n",
       "      <td>1.848</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.439</td>\n",
       "      <td>18.402</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.992</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>12.798</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.431</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>3.366</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.858</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-0.870</td>\n",
       "      <td>-0.892</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-0.881</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.840</td>\n",
       "      <td>6.295</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>31857.094</td>\n",
       "      <td>3120.121</td>\n",
       "      <td>333.854</td>\n",
       "      <td>1.131</td>\n",
       "      <td>2.790</td>\n",
       "      <td>1.711</td>\n",
       "      <td>5806.973</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.315</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.706</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.124</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1.892</td>\n",
       "      <td>0.272</td>\n",
       "      <td>49.774</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.596</td>\n",
       "      <td>6.838</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.156</td>\n",
       "      <td>0.699</td>\n",
       "      <td>2.270</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.508</td>\n",
       "      <td>1.680</td>\n",
       "      <td>25.858</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>1.594</td>\n",
       "      <td>15.015</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.346</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.123</td>\n",
       "      <td>38.187</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.144</td>\n",
       "      <td>1.495</td>\n",
       "      <td>0.570</td>\n",
       "      <td>47046.269</td>\n",
       "      <td>2995.717</td>\n",
       "      <td>586.260</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.715</td>\n",
       "      <td>10286.320</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13335.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>291.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20013.000</td>\n",
       "      <td>2437.000</td>\n",
       "      <td>155.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1796.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36024.000</td>\n",
       "      <td>6054.000</td>\n",
       "      <td>344.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>10791.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>44.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>174.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>4165.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>231.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>26.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>174.000</td>\n",
       "      <td>1286.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>174.000</td>\n",
       "      <td>1232.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>4094.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>38.402</td>\n",
       "      <td>1.000</td>\n",
       "      <td>395754.000</td>\n",
       "      <td>17775.000</td>\n",
       "      <td>22574.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>604800.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  qty_exclamation_url  qty_space_url  qty_tilde_url  qty_comma_url  qty_plus_url  qty_asterisk_url  qty_hashtag_url  qty_dollar_url  qty_percent_url  qty_tld_url  length_url  qty_dot_domain  qty_hyphen_domain  qty_underline_domain  qty_slash_domain  qty_questionmark_domain  qty_equal_domain  qty_at_domain  qty_and_domain  qty_exclamation_domain  qty_space_domain  \\\n",
       "count   129698.000      129698.000         129698.000     129698.000            129698.000     129698.000  129698.000   129698.000           129698.000     129698.000     129698.000     129698.000    129698.000        129698.000       129698.000      129698.000       129698.000   129698.000  129698.000      129698.000         129698.000            129698.000        129698.000               129698.000        129698.000     129698.000      129698.000              129698.000        129698.000   \n",
       "mean         2.221           0.370              0.132          1.490                 0.011          0.240       0.026        0.164                0.004          0.001          0.004          0.002         0.003             0.005            0.001           0.002            0.124        1.054      39.098           1.848              0.120                 0.001             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000   \n",
       "std          1.315           1.200              0.706          1.964                 0.124          1.027       0.293        0.992                0.098          0.081          0.084          0.077         0.125             0.336            0.068           0.102            1.892        0.272      49.774           0.738              0.436                 0.029             0.000                    0.000             0.000          0.003           0.000                   0.000             0.000   \n",
       "min          1.000           0.000              0.000          0.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        0.000       4.000           0.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000   \n",
       "25%          2.000           0.000              0.000          0.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        1.000      17.000           1.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000   \n",
       "50%          2.000           0.000              0.000          1.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        1.000      23.000           2.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000   \n",
       "75%          2.000           0.000              0.000          3.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        1.000      43.000           2.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000   \n",
       "max         24.000          35.000             21.000         44.000                 9.000         23.000      43.000       26.000               10.000          9.000          5.000         11.000        19.000            60.000           13.000          10.000          174.000       12.000    4165.000          21.000             11.000                 3.000             0.000                    0.000             0.000          1.000           0.000                   0.000             0.000   \n",
       "\n",
       "       qty_tilde_domain  qty_comma_domain  qty_plus_domain  qty_asterisk_domain  qty_hashtag_domain  qty_dollar_domain  qty_percent_domain  qty_vowels_domain  domain_length  domain_in_ip  server_client_domain  qty_dot_directory  qty_hyphen_directory  qty_underline_directory  qty_slash_directory  qty_questionmark_directory  qty_equal_directory  qty_at_directory  qty_and_directory  qty_exclamation_directory  qty_space_directory  qty_tilde_directory  qty_comma_directory  qty_plus_directory  \\\n",
       "count        129698.000        129698.000       129698.000           129698.000          129698.000         129698.000          129698.000         129698.000     129698.000    129698.000            129698.000         129698.000            129698.000               129698.000           129698.000                  129698.000           129698.000        129698.000         129698.000                 129698.000           129698.000           129698.000           129698.000          129698.000   \n",
       "mean              0.000             0.000            0.000                0.000               0.000              0.000               0.000              5.439         18.402         0.003                 0.004             -0.213                -0.256                   -0.393                0.992                      -0.460               -0.451            -0.456             -0.455                     -0.458               -0.459               -0.457               -0.459              -0.459   \n",
       "std               0.000             0.000            0.000                0.000               0.000              0.000               0.000              2.596          6.838         0.052                 0.065              0.928                 1.156                    0.699                2.270                       0.498                0.520             0.554              0.540                      0.504                0.505                0.509                0.501               0.510   \n",
       "min               0.000             0.000            0.000                0.000               0.000              0.000               0.000              0.000          4.000         0.000                 0.000             -1.000                -1.000                   -1.000               -1.000                      -1.000               -1.000            -1.000             -1.000                     -1.000               -1.000               -1.000               -1.000              -1.000   \n",
       "25%               0.000             0.000            0.000                0.000               0.000              0.000               0.000              4.000         14.000         0.000                 0.000             -1.000                -1.000                   -1.000               -1.000                      -1.000               -1.000            -1.000             -1.000                     -1.000               -1.000               -1.000               -1.000              -1.000   \n",
       "50%               0.000             0.000            0.000                0.000               0.000              0.000               0.000              5.000         17.000         0.000                 0.000              0.000                 0.000                    0.000                1.000                       0.000                0.000             0.000              0.000                      0.000                0.000                0.000                0.000               0.000   \n",
       "75%               0.000             0.000            0.000                0.000               0.000              0.000               0.000              7.000         22.000         0.000                 0.000              0.000                 0.000                    0.000                3.000                       0.000                0.000             0.000              0.000                      0.000                0.000                0.000                0.000               0.000   \n",
       "max               0.000             0.000            0.000                0.000               0.000              0.000               0.000             61.000        231.000         1.000                 1.000             19.000                23.000                   17.000               22.000                       0.000                5.000            43.000             26.000                      9.000                9.000                5.000                5.000              19.000   \n",
       "\n",
       "       qty_asterisk_directory  qty_hashtag_directory  qty_dollar_directory  qty_percent_directory  directory_length  qty_dot_file  qty_hyphen_file  qty_underline_file  qty_slash_file  qty_questionmark_file  qty_equal_file  qty_at_file  qty_and_file  qty_exclamation_file  qty_space_file  qty_tilde_file  qty_comma_file  qty_plus_file  qty_asterisk_file  qty_hashtag_file  qty_dollar_file  qty_percent_file  file_length  qty_dot_params  qty_hyphen_params  qty_underline_params  qty_slash_params  \\\n",
       "count              129698.000             129698.000            129698.000             129698.000        129698.000    129698.000       129698.000          129698.000      129698.000             129698.000      129698.000   129698.000    129698.000            129698.000      129698.000      129698.000      129698.000     129698.000         129698.000        129698.000       129698.000        129698.000   129698.000      129698.000         129698.000            129698.000        129698.000   \n",
       "mean                   -0.456                 -0.460                -0.459                 -0.399            12.798        -0.266           -0.393              -0.431          -0.460                 -0.460          -0.458       -0.460        -0.459                -0.459          -0.460          -0.460          -0.460         -0.459             -0.459            -0.460           -0.460            -0.416        3.366          -0.781             -0.858                -0.839            -0.870   \n",
       "std                     0.597                  0.498                 0.508                  1.680            25.858         0.781            0.830               0.614           0.498                  0.498           0.503        0.499         0.502                 0.501           0.502           0.500           0.501          0.508              0.561             0.498            0.498             1.594       15.015           1.045              0.684                 0.705             0.588   \n",
       "min                    -1.000                 -1.000                -1.000                 -1.000            -1.000        -1.000           -1.000              -1.000          -1.000                 -1.000          -1.000       -1.000        -1.000                -1.000          -1.000          -1.000          -1.000         -1.000             -1.000            -1.000           -1.000            -1.000       -1.000          -1.000             -1.000                -1.000            -1.000   \n",
       "25%                    -1.000                 -1.000                -1.000                 -1.000            -1.000        -1.000           -1.000              -1.000          -1.000                 -1.000          -1.000       -1.000        -1.000                -1.000          -1.000          -1.000          -1.000         -1.000             -1.000            -1.000           -1.000            -1.000       -1.000          -1.000             -1.000                -1.000            -1.000   \n",
       "50%                     0.000                  0.000                 0.000                  0.000             1.000         0.000            0.000               0.000           0.000                  0.000           0.000        0.000         0.000                 0.000           0.000           0.000           0.000          0.000              0.000             0.000            0.000             0.000        0.000          -1.000             -1.000                -1.000            -1.000   \n",
       "75%                     0.000                  0.000                 0.000                  0.000            20.000         0.000            0.000               0.000           0.000                  0.000           0.000        0.000         0.000                 0.000           0.000           0.000           0.000          0.000              0.000             0.000            0.000             0.000        5.000          -1.000             -1.000                -1.000            -1.000   \n",
       "max                    60.000                  0.000                10.000                174.000          1286.000        12.000           21.000              17.000           0.000                  0.000           3.000        2.000         3.000                 4.000           9.000           4.000           5.000         19.000             60.000             0.000            0.000           174.000     1232.000          23.000             35.000                21.000            43.000   \n",
       "\n",
       "       qty_questionmark_params  qty_equal_params  qty_at_params  qty_and_params  qty_exclamation_params  qty_space_params  qty_tilde_params  qty_comma_params  qty_plus_params  qty_asterisk_params  qty_hashtag_params  qty_dollar_params  qty_percent_params  params_length  tld_present_params  qty_params  email_in_url  time_response  domain_spf     asn_ip  time_domain_activation  time_domain_expiration  qty_ip_resolved  qty_nameservers  qty_mx_servers  ttl_hostname  tls_ssl_certificate  \\\n",
       "count               129698.000        129698.000     129698.000      129698.000              129698.000        129698.000        129698.000        129698.000       129698.000           129698.000          129698.000         129698.000          129698.000     129698.000          129698.000  129698.000    129698.000     129698.000  129698.000 129698.000              129698.000              129698.000       129698.000       129698.000      129698.000    129698.000           129698.000   \n",
       "mean                    -0.892            -0.682         -0.881          -0.754                  -0.902            -0.902            -0.902            -0.901           -0.900               -0.902              -0.902             -0.902              -0.840          6.295              -0.874      -0.720         0.021          0.787      -0.022  31857.094                3120.121                 333.854            1.131            2.790           1.711      5806.973                0.505   \n",
       "std                      0.346             1.193          0.386           1.088                   0.304             0.298             0.297             0.308            0.311                0.298               0.297              0.300               1.123         38.187               0.409       1.010         0.144          1.495       0.570  47046.269                2995.717                 586.260            0.904            1.340           1.715     10286.320                0.500   \n",
       "min                     -1.000            -1.000         -1.000          -1.000                  -1.000            -1.000            -1.000            -1.000           -1.000               -1.000              -1.000             -1.000              -1.000         -1.000              -1.000      -1.000         0.000         -1.000      -1.000     -1.000                  -1.000                  -1.000           -1.000            0.000           0.000        -1.000                0.000   \n",
       "25%                     -1.000            -1.000         -1.000          -1.000                  -1.000            -1.000            -1.000            -1.000           -1.000               -1.000              -1.000             -1.000              -1.000         -1.000              -1.000      -1.000         0.000          0.234       0.000  13335.000                  -1.000                  -1.000            1.000            2.000           1.000       291.000                0.000   \n",
       "50%                     -1.000            -1.000         -1.000          -1.000                  -1.000            -1.000            -1.000            -1.000           -1.000               -1.000              -1.000             -1.000              -1.000         -1.000              -1.000      -1.000         0.000          0.454       0.000  20013.000                2437.000                 155.000            1.000            2.000           1.000      1796.000                1.000   \n",
       "75%                     -1.000            -1.000         -1.000          -1.000                  -1.000            -1.000            -1.000            -1.000           -1.000               -1.000              -1.000             -1.000              -1.000         -1.000              -1.000      -1.000         0.000          0.867       0.000  36024.000                6054.000                 344.000            1.000            4.000           2.000     10791.000                1.000   \n",
       "max                      9.000            23.000         10.000          22.000                  10.000             4.000             1.000            11.000            6.000                4.000               0.000              4.000              65.000       4094.000               1.000      23.000         1.000         38.402       1.000 395754.000               17775.000               22574.000           24.000           20.000          20.000    604800.000                1.000   \n",
       "\n",
       "       qty_redirects  url_google_index  domain_google_index  url_shortened   phishing  \n",
       "count     129698.000        129698.000           129698.000     129698.000 129698.000  \n",
       "mean           0.332             0.001                0.002          0.006      0.402  \n",
       "std            0.794             0.053                0.058          0.080      0.490  \n",
       "min           -1.000            -1.000               -1.000          0.000      0.000  \n",
       "25%            0.000             0.000                0.000          0.000      0.000  \n",
       "50%            0.000             0.000                0.000          0.000      0.000  \n",
       "75%            1.000             0.000                0.000          0.000      1.000  \n",
       "max           17.000             1.000                1.000          1.000      1.000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of data\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "any(data<0)\n",
    "# data.dropna(inplace=True)\n",
    "# data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of fraud label\n",
    "\n",
    "# numerical_column = \"time_response\"\n",
    "# category_columns = data.columns.drop(\"time_response\")\n",
    "\n",
    "data[\"phishing\"].value_counts().sort_index().plot.bar(x=\"Target Value\", y=\"Number of Occurrences\", title=\"Distribution of Fraud Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram\n",
    "# plt.hist(data[\"numerical_column\"], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "# plt.title(\"Histogram of Numerical Column\")\n",
    "# plt.xlabel(\"Value\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n",
    "\n",
    "# # Box plot\n",
    "# plt.boxplot(data[\"numerical_column\"])\n",
    "# plt.title(\"Box plot of Numerical Column\")\n",
    "# plt.ylabel(\"Value\")\n",
    "# plt.show()\n",
    "\n",
    "# # Scatter plot\n",
    "# plt.scatter(data[\"numerical_column1\"], data[\"numerical_column2\"], color=\"green\")\n",
    "# plt.title(\"Scatter plot of Numerical Column1 vs Numerical Column2\")\n",
    "# plt.xlabel(\"Numerical Column1\")\n",
    "# plt.ylabel(\"Numerical Column2\")\n",
    "# plt.show()\n",
    "\n",
    "# # Line plot\n",
    "# plt.plot(data[\"index_column\"], data[\"numerical_column\"], marker=\"o\", color=\"blue\", linestyle=\"-\")\n",
    "# plt.title(\"Line plot of Numerical Column over Index Column\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Numerical Column\")\n",
    "# plt.show()\n",
    "\n",
    "# # Bar plot\n",
    "# plt.bar(data[\"category_column\"], data[\"numerical_column\"], color=\"orange\")\n",
    "# plt.title(\"Bar plot of Numerical Column across Categories\")\n",
    "# plt.xlabel(\"Category\")\n",
    "# plt.ylabel(\"Numerical Column\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant column if min==max\n",
    "remove_cols = []\n",
    "for col in data.columns:\n",
    "    if data[col].min() == data[col].max():\n",
    "        remove_cols.append(col)\n",
    "data = data.drop(remove_cols, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further feature selection could be done after evaluating feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qty_dot_url                   0\n",
       "qty_hyphen_url                0\n",
       "qty_underline_url             0\n",
       "qty_slash_url                 0\n",
       "qty_questionmark_url          0\n",
       "qty_equal_url                 0\n",
       "qty_at_url                    0\n",
       "qty_and_url                   0\n",
       "qty_exclamation_url           0\n",
       "qty_space_url                 0\n",
       "qty_tilde_url                 0\n",
       "qty_comma_url                 0\n",
       "qty_plus_url                  0\n",
       "qty_asterisk_url              0\n",
       "qty_hashtag_url               0\n",
       "qty_dollar_url                0\n",
       "qty_percent_url               0\n",
       "qty_tld_url                   0\n",
       "length_url                    0\n",
       "qty_dot_domain                0\n",
       "qty_hyphen_domain             0\n",
       "qty_underline_domain          0\n",
       "qty_at_domain                 0\n",
       "qty_vowels_domain             0\n",
       "domain_length                 0\n",
       "domain_in_ip                  0\n",
       "server_client_domain          0\n",
       "qty_dot_directory             0\n",
       "qty_hyphen_directory          0\n",
       "qty_underline_directory       0\n",
       "qty_slash_directory           0\n",
       "qty_questionmark_directory    0\n",
       "qty_equal_directory           0\n",
       "qty_at_directory              0\n",
       "qty_and_directory             0\n",
       "qty_exclamation_directory     0\n",
       "qty_space_directory           0\n",
       "qty_tilde_directory           0\n",
       "qty_comma_directory           0\n",
       "qty_plus_directory            0\n",
       "qty_asterisk_directory        0\n",
       "qty_hashtag_directory         0\n",
       "qty_dollar_directory          0\n",
       "qty_percent_directory         0\n",
       "directory_length              0\n",
       "qty_dot_file                  0\n",
       "qty_hyphen_file               0\n",
       "qty_underline_file            0\n",
       "qty_slash_file                0\n",
       "qty_questionmark_file         0\n",
       "qty_equal_file                0\n",
       "qty_at_file                   0\n",
       "qty_and_file                  0\n",
       "qty_exclamation_file          0\n",
       "qty_space_file                0\n",
       "qty_tilde_file                0\n",
       "qty_comma_file                0\n",
       "qty_plus_file                 0\n",
       "qty_asterisk_file             0\n",
       "qty_hashtag_file              0\n",
       "qty_dollar_file               0\n",
       "qty_percent_file              0\n",
       "file_length                   0\n",
       "qty_dot_params                0\n",
       "qty_hyphen_params             0\n",
       "qty_underline_params          0\n",
       "qty_slash_params              0\n",
       "qty_questionmark_params       0\n",
       "qty_equal_params              0\n",
       "qty_at_params                 0\n",
       "qty_and_params                0\n",
       "qty_exclamation_params        0\n",
       "qty_space_params              0\n",
       "qty_tilde_params              0\n",
       "qty_comma_params              0\n",
       "qty_plus_params               0\n",
       "qty_asterisk_params           0\n",
       "qty_hashtag_params            0\n",
       "qty_dollar_params             0\n",
       "qty_percent_params            0\n",
       "params_length                 0\n",
       "tld_present_params            0\n",
       "qty_params                    0\n",
       "email_in_url                  0\n",
       "time_response                 0\n",
       "domain_spf                    0\n",
       "asn_ip                        0\n",
       "time_domain_activation        0\n",
       "time_domain_expiration        0\n",
       "qty_ip_resolved               0\n",
       "qty_nameservers               0\n",
       "qty_mx_servers                0\n",
       "ttl_hostname                  0\n",
       "tls_ssl_certificate           0\n",
       "qty_redirects                 0\n",
       "url_google_index              0\n",
       "domain_google_index           0\n",
       "url_shortened                 0\n",
       "phishing                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all columns except the last one\n",
    "cols_to_scale = data.columns[:-1]\n",
    "\n",
    "# Apply the operation to selected columns\n",
    "data[cols_to_scale] = (data[cols_to_scale] - data[cols_to_scale].min()) / \\\n",
    "                      (data[cols_to_scale].max() - data[cols_to_scale].min())\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129698 entries, 0 to 129697\n",
      "Data columns (total 99 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   qty_dot_url                 129698 non-null  float64\n",
      " 1   qty_hyphen_url              129698 non-null  float64\n",
      " 2   qty_underline_url           129698 non-null  float64\n",
      " 3   qty_slash_url               129698 non-null  float64\n",
      " 4   qty_questionmark_url        129698 non-null  float64\n",
      " 5   qty_equal_url               129698 non-null  float64\n",
      " 6   qty_at_url                  129698 non-null  float64\n",
      " 7   qty_and_url                 129698 non-null  float64\n",
      " 8   qty_exclamation_url         129698 non-null  float64\n",
      " 9   qty_space_url               129698 non-null  float64\n",
      " 10  qty_tilde_url               129698 non-null  float64\n",
      " 11  qty_comma_url               129698 non-null  float64\n",
      " 12  qty_plus_url                129698 non-null  float64\n",
      " 13  qty_asterisk_url            129698 non-null  float64\n",
      " 14  qty_hashtag_url             129698 non-null  float64\n",
      " 15  qty_dollar_url              129698 non-null  float64\n",
      " 16  qty_percent_url             129698 non-null  float64\n",
      " 17  qty_tld_url                 129698 non-null  float64\n",
      " 18  length_url                  129698 non-null  float64\n",
      " 19  qty_dot_domain              129698 non-null  float64\n",
      " 20  qty_hyphen_domain           129698 non-null  float64\n",
      " 21  qty_underline_domain        129698 non-null  float64\n",
      " 22  qty_at_domain               129698 non-null  float64\n",
      " 23  qty_vowels_domain           129698 non-null  float64\n",
      " 24  domain_length               129698 non-null  float64\n",
      " 25  domain_in_ip                129698 non-null  float64\n",
      " 26  server_client_domain        129698 non-null  float64\n",
      " 27  qty_dot_directory           129698 non-null  float64\n",
      " 28  qty_hyphen_directory        129698 non-null  float64\n",
      " 29  qty_underline_directory     129698 non-null  float64\n",
      " 30  qty_slash_directory         129698 non-null  float64\n",
      " 31  qty_questionmark_directory  129698 non-null  float64\n",
      " 32  qty_equal_directory         129698 non-null  float64\n",
      " 33  qty_at_directory            129698 non-null  float64\n",
      " 34  qty_and_directory           129698 non-null  float64\n",
      " 35  qty_exclamation_directory   129698 non-null  float64\n",
      " 36  qty_space_directory         129698 non-null  float64\n",
      " 37  qty_tilde_directory         129698 non-null  float64\n",
      " 38  qty_comma_directory         129698 non-null  float64\n",
      " 39  qty_plus_directory          129698 non-null  float64\n",
      " 40  qty_asterisk_directory      129698 non-null  float64\n",
      " 41  qty_hashtag_directory       129698 non-null  float64\n",
      " 42  qty_dollar_directory        129698 non-null  float64\n",
      " 43  qty_percent_directory       129698 non-null  float64\n",
      " 44  directory_length            129698 non-null  float64\n",
      " 45  qty_dot_file                129698 non-null  float64\n",
      " 46  qty_hyphen_file             129698 non-null  float64\n",
      " 47  qty_underline_file          129698 non-null  float64\n",
      " 48  qty_slash_file              129698 non-null  float64\n",
      " 49  qty_questionmark_file       129698 non-null  float64\n",
      " 50  qty_equal_file              129698 non-null  float64\n",
      " 51  qty_at_file                 129698 non-null  float64\n",
      " 52  qty_and_file                129698 non-null  float64\n",
      " 53  qty_exclamation_file        129698 non-null  float64\n",
      " 54  qty_space_file              129698 non-null  float64\n",
      " 55  qty_tilde_file              129698 non-null  float64\n",
      " 56  qty_comma_file              129698 non-null  float64\n",
      " 57  qty_plus_file               129698 non-null  float64\n",
      " 58  qty_asterisk_file           129698 non-null  float64\n",
      " 59  qty_hashtag_file            129698 non-null  float64\n",
      " 60  qty_dollar_file             129698 non-null  float64\n",
      " 61  qty_percent_file            129698 non-null  float64\n",
      " 62  file_length                 129698 non-null  float64\n",
      " 63  qty_dot_params              129698 non-null  float64\n",
      " 64  qty_hyphen_params           129698 non-null  float64\n",
      " 65  qty_underline_params        129698 non-null  float64\n",
      " 66  qty_slash_params            129698 non-null  float64\n",
      " 67  qty_questionmark_params     129698 non-null  float64\n",
      " 68  qty_equal_params            129698 non-null  float64\n",
      " 69  qty_at_params               129698 non-null  float64\n",
      " 70  qty_and_params              129698 non-null  float64\n",
      " 71  qty_exclamation_params      129698 non-null  float64\n",
      " 72  qty_space_params            129698 non-null  float64\n",
      " 73  qty_tilde_params            129698 non-null  float64\n",
      " 74  qty_comma_params            129698 non-null  float64\n",
      " 75  qty_plus_params             129698 non-null  float64\n",
      " 76  qty_asterisk_params         129698 non-null  float64\n",
      " 77  qty_hashtag_params          129698 non-null  float64\n",
      " 78  qty_dollar_params           129698 non-null  float64\n",
      " 79  qty_percent_params          129698 non-null  float64\n",
      " 80  params_length               129698 non-null  float64\n",
      " 81  tld_present_params          129698 non-null  float64\n",
      " 82  qty_params                  129698 non-null  float64\n",
      " 83  email_in_url                129698 non-null  float64\n",
      " 84  time_response               129698 non-null  float64\n",
      " 85  domain_spf                  129698 non-null  float64\n",
      " 86  asn_ip                      129698 non-null  float64\n",
      " 87  time_domain_activation      129698 non-null  float64\n",
      " 88  time_domain_expiration      129698 non-null  float64\n",
      " 89  qty_ip_resolved             129698 non-null  float64\n",
      " 90  qty_nameservers             129698 non-null  float64\n",
      " 91  qty_mx_servers              129698 non-null  float64\n",
      " 92  ttl_hostname                129698 non-null  float64\n",
      " 93  tls_ssl_certificate         129698 non-null  float64\n",
      " 94  qty_redirects               129698 non-null  float64\n",
      " 95  url_google_index            129698 non-null  float64\n",
      " 96  domain_google_index         129698 non-null  float64\n",
      " 97  url_shortened               129698 non-null  float64\n",
      " 98  phishing                    129698 non-null  int64  \n",
      "dtypes: float64(98), int64(1)\n",
      "memory usage: 98.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>qty_tilde_url</th>\n",
       "      <th>qty_comma_url</th>\n",
       "      <th>qty_plus_url</th>\n",
       "      <th>qty_asterisk_url</th>\n",
       "      <th>qty_hashtag_url</th>\n",
       "      <th>qty_dollar_url</th>\n",
       "      <th>qty_percent_url</th>\n",
       "      <th>qty_tld_url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>qty_dot_domain</th>\n",
       "      <th>qty_hyphen_domain</th>\n",
       "      <th>qty_underline_domain</th>\n",
       "      <th>qty_at_domain</th>\n",
       "      <th>qty_vowels_domain</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_in_ip</th>\n",
       "      <th>server_client_domain</th>\n",
       "      <th>qty_dot_directory</th>\n",
       "      <th>qty_hyphen_directory</th>\n",
       "      <th>qty_underline_directory</th>\n",
       "      <th>qty_slash_directory</th>\n",
       "      <th>qty_questionmark_directory</th>\n",
       "      <th>qty_equal_directory</th>\n",
       "      <th>qty_at_directory</th>\n",
       "      <th>qty_and_directory</th>\n",
       "      <th>qty_exclamation_directory</th>\n",
       "      <th>qty_space_directory</th>\n",
       "      <th>qty_tilde_directory</th>\n",
       "      <th>qty_comma_directory</th>\n",
       "      <th>qty_plus_directory</th>\n",
       "      <th>qty_asterisk_directory</th>\n",
       "      <th>qty_hashtag_directory</th>\n",
       "      <th>qty_dollar_directory</th>\n",
       "      <th>qty_percent_directory</th>\n",
       "      <th>directory_length</th>\n",
       "      <th>qty_dot_file</th>\n",
       "      <th>qty_hyphen_file</th>\n",
       "      <th>qty_underline_file</th>\n",
       "      <th>qty_slash_file</th>\n",
       "      <th>qty_questionmark_file</th>\n",
       "      <th>qty_equal_file</th>\n",
       "      <th>qty_at_file</th>\n",
       "      <th>qty_and_file</th>\n",
       "      <th>qty_exclamation_file</th>\n",
       "      <th>qty_space_file</th>\n",
       "      <th>qty_tilde_file</th>\n",
       "      <th>qty_comma_file</th>\n",
       "      <th>qty_plus_file</th>\n",
       "      <th>qty_asterisk_file</th>\n",
       "      <th>qty_hashtag_file</th>\n",
       "      <th>qty_dollar_file</th>\n",
       "      <th>qty_percent_file</th>\n",
       "      <th>file_length</th>\n",
       "      <th>qty_dot_params</th>\n",
       "      <th>qty_hyphen_params</th>\n",
       "      <th>qty_underline_params</th>\n",
       "      <th>qty_slash_params</th>\n",
       "      <th>qty_questionmark_params</th>\n",
       "      <th>qty_equal_params</th>\n",
       "      <th>qty_at_params</th>\n",
       "      <th>qty_and_params</th>\n",
       "      <th>qty_exclamation_params</th>\n",
       "      <th>qty_space_params</th>\n",
       "      <th>qty_tilde_params</th>\n",
       "      <th>qty_comma_params</th>\n",
       "      <th>qty_plus_params</th>\n",
       "      <th>qty_asterisk_params</th>\n",
       "      <th>qty_hashtag_params</th>\n",
       "      <th>qty_dollar_params</th>\n",
       "      <th>qty_percent_params</th>\n",
       "      <th>params_length</th>\n",
       "      <th>tld_present_params</th>\n",
       "      <th>qty_params</th>\n",
       "      <th>email_in_url</th>\n",
       "      <th>time_response</th>\n",
       "      <th>domain_spf</th>\n",
       "      <th>asn_ip</th>\n",
       "      <th>time_domain_activation</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "      <td>129698.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.087</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.056</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.056</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.018</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  qty_exclamation_url  qty_space_url  qty_tilde_url  qty_comma_url  qty_plus_url  qty_asterisk_url  qty_hashtag_url  qty_dollar_url  qty_percent_url  qty_tld_url  length_url  qty_dot_domain  qty_hyphen_domain  qty_underline_domain  qty_at_domain  qty_vowels_domain  domain_length  domain_in_ip  server_client_domain  qty_dot_directory  qty_hyphen_directory  \\\n",
       "count   129698.000      129698.000         129698.000     129698.000            129698.000     129698.000  129698.000   129698.000           129698.000     129698.000     129698.000     129698.000    129698.000        129698.000       129698.000      129698.000       129698.000   129698.000  129698.000      129698.000         129698.000            129698.000     129698.000         129698.000     129698.000    129698.000            129698.000         129698.000            129698.000   \n",
       "mean         0.053           0.011              0.006          0.034                 0.001          0.010       0.001        0.006                0.000          0.000          0.001          0.000         0.000             0.000            0.000           0.000            0.001        0.088       0.008           0.088              0.011                 0.000          0.000              0.089          0.063         0.003                 0.004              0.039                 0.031   \n",
       "std          0.057           0.034              0.034          0.045                 0.014          0.045       0.007        0.038                0.010          0.009          0.017          0.007         0.007             0.006            0.005           0.010            0.011        0.023       0.012           0.035              0.040                 0.010          0.003              0.043          0.030         0.052                 0.065              0.046                 0.048   \n",
       "min          0.000           0.000              0.000          0.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        0.000       0.000           0.000              0.000                 0.000          0.000              0.000          0.000         0.000                 0.000              0.000                 0.000   \n",
       "25%          0.043           0.000              0.000          0.000                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        0.083       0.003           0.048              0.000                 0.000          0.000              0.066          0.044         0.000                 0.000              0.000                 0.000   \n",
       "50%          0.043           0.000              0.000          0.023                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        0.083       0.005           0.095              0.000                 0.000          0.000              0.082          0.057         0.000                 0.000              0.050                 0.042   \n",
       "75%          0.043           0.000              0.000          0.068                 0.000          0.000       0.000        0.000                0.000          0.000          0.000          0.000         0.000             0.000            0.000           0.000            0.000        0.083       0.009           0.095              0.000                 0.000          0.000              0.115          0.079         0.000                 0.000              0.050                 0.042   \n",
       "max          1.000           1.000              1.000          1.000                 1.000          1.000       1.000        1.000                1.000          1.000          1.000          1.000         1.000             1.000            1.000           1.000            1.000        1.000       1.000           1.000              1.000                 1.000          1.000              1.000          1.000         1.000                 1.000              1.000                 1.000   \n",
       "\n",
       "       qty_underline_directory  qty_slash_directory  qty_questionmark_directory  qty_equal_directory  qty_at_directory  qty_and_directory  qty_exclamation_directory  qty_space_directory  qty_tilde_directory  qty_comma_directory  qty_plus_directory  qty_asterisk_directory  qty_hashtag_directory  qty_dollar_directory  qty_percent_directory  directory_length  qty_dot_file  qty_hyphen_file  qty_underline_file  qty_slash_file  qty_questionmark_file  qty_equal_file  qty_at_file  qty_and_file  \\\n",
       "count               129698.000           129698.000                  129698.000           129698.000        129698.000         129698.000                 129698.000           129698.000           129698.000           129698.000          129698.000              129698.000             129698.000            129698.000             129698.000        129698.000    129698.000       129698.000          129698.000      129698.000             129698.000      129698.000   129698.000    129698.000   \n",
       "mean                     0.034                0.087                       0.540                0.091             0.012              0.020                      0.054                0.054                0.091                0.090               0.027                   0.009                  0.540                 0.049                  0.003             0.011         0.056            0.028               0.032           0.540                  0.540           0.135        0.180         0.135   \n",
       "std                      0.039                0.099                       0.498                0.087             0.013              0.020                      0.050                0.051                0.085                0.084               0.026                   0.010                  0.498                 0.046                  0.010             0.020         0.060            0.038               0.034           0.498                  0.498           0.126        0.166         0.125   \n",
       "min                      0.000                0.000                       0.000                0.000             0.000              0.000                      0.000                0.000                0.000                0.000               0.000                   0.000                  0.000                 0.000                  0.000             0.000         0.000            0.000               0.000           0.000                  0.000           0.000        0.000         0.000   \n",
       "25%                      0.000                0.000                       0.000                0.000             0.000              0.000                      0.000                0.000                0.000                0.000               0.000                   0.000                  0.000                 0.000                  0.000             0.000         0.000            0.000               0.000           0.000                  0.000           0.000        0.000         0.000   \n",
       "50%                      0.056                0.087                       1.000                0.167             0.023              0.037                      0.100                0.100                0.167                0.167               0.050                   0.016                  1.000                 0.091                  0.006             0.002         0.077            0.045               0.056           1.000                  1.000           0.250        0.333         0.250   \n",
       "75%                      0.056                0.174                       1.000                0.167             0.023              0.037                      0.100                0.100                0.167                0.167               0.050                   0.016                  1.000                 0.091                  0.006             0.016         0.077            0.045               0.056           1.000                  1.000           0.250        0.333         0.250   \n",
       "max                      1.000                1.000                       1.000                1.000             1.000              1.000                      1.000                1.000                1.000                1.000               1.000                   1.000                  1.000                 1.000                  1.000             1.000         1.000            1.000               1.000           1.000                  1.000           1.000        1.000         1.000   \n",
       "\n",
       "       qty_exclamation_file  qty_space_file  qty_tilde_file  qty_comma_file  qty_plus_file  qty_asterisk_file  qty_hashtag_file  qty_dollar_file  qty_percent_file  file_length  qty_dot_params  qty_hyphen_params  qty_underline_params  qty_slash_params  qty_questionmark_params  qty_equal_params  qty_at_params  qty_and_params  qty_exclamation_params  qty_space_params  qty_tilde_params  qty_comma_params  qty_plus_params  qty_asterisk_params  qty_hashtag_params  qty_dollar_params  \\\n",
       "count            129698.000      129698.000      129698.000      129698.000     129698.000         129698.000        129698.000       129698.000        129698.000   129698.000      129698.000         129698.000            129698.000        129698.000               129698.000        129698.000     129698.000      129698.000              129698.000        129698.000        129698.000        129698.000       129698.000           129698.000          129698.000         129698.000   \n",
       "mean                  0.108           0.054           0.108           0.090          0.027              0.009             0.540            0.540             0.003        0.004           0.009              0.004                 0.007             0.003                    0.011             0.013          0.011           0.011                   0.009             0.020             0.049             0.008            0.014                0.020               0.098              0.020   \n",
       "std                   0.100           0.050           0.100           0.084          0.025              0.009             0.498            0.498             0.009        0.012           0.044              0.019                 0.032             0.013                    0.035             0.050          0.035           0.047                   0.028             0.060             0.149             0.026            0.044                0.060               0.297              0.060   \n",
       "min                   0.000           0.000           0.000           0.000          0.000              0.000             0.000            0.000             0.000        0.000           0.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000             0.000             0.000            0.000                0.000               0.000              0.000   \n",
       "25%                   0.000           0.000           0.000           0.000          0.000              0.000             0.000            0.000             0.000        0.000           0.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000             0.000             0.000            0.000                0.000               0.000              0.000   \n",
       "50%                   0.200           0.100           0.200           0.167          0.050              0.016             1.000            1.000             0.006        0.001           0.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000             0.000             0.000            0.000                0.000               0.000              0.000   \n",
       "75%                   0.200           0.100           0.200           0.167          0.050              0.016             1.000            1.000             0.006        0.005           0.000              0.000                 0.000             0.000                    0.000             0.000          0.000           0.000                   0.000             0.000             0.000             0.000            0.000                0.000               0.000              0.000   \n",
       "max                   1.000           1.000           1.000           1.000          1.000              1.000             1.000            1.000             1.000        1.000           1.000              1.000                 1.000             1.000                    1.000             1.000          1.000           1.000                   1.000             1.000             1.000             1.000            1.000                1.000               1.000              1.000   \n",
       "\n",
       "       qty_percent_params  params_length  tld_present_params  qty_params  email_in_url  time_response  domain_spf     asn_ip  time_domain_activation  time_domain_expiration  qty_ip_resolved  qty_nameservers  qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  url_google_index  domain_google_index  url_shortened   phishing  \n",
       "count          129698.000     129698.000          129698.000  129698.000    129698.000     129698.000  129698.000 129698.000              129698.000              129698.000       129698.000       129698.000      129698.000    129698.000           129698.000     129698.000        129698.000           129698.000     129698.000 129698.000  \n",
       "mean                0.002          0.002               0.063       0.012         0.021          0.045       0.489      0.080                   0.176                   0.015            0.085            0.140           0.086         0.010                0.505          0.074             0.501                0.501          0.006      0.402  \n",
       "std                 0.017          0.009               0.204       0.042         0.144          0.038       0.285      0.119                   0.169                   0.026            0.036            0.067           0.086         0.017                0.500          0.044             0.026                0.029          0.080      0.490  \n",
       "min                 0.000          0.000               0.000       0.000         0.000          0.000       0.000      0.000                   0.000                   0.000            0.000            0.000           0.000         0.000                0.000          0.000             0.000                0.000          0.000      0.000  \n",
       "25%                 0.000          0.000               0.000       0.000         0.000          0.031       0.500      0.034                   0.000                   0.000            0.080            0.100           0.050         0.000                0.000          0.056             0.500                0.500          0.000      0.000  \n",
       "50%                 0.000          0.000               0.000       0.000         0.000          0.037       0.500      0.051                   0.137                   0.007            0.080            0.100           0.050         0.003                1.000          0.056             0.500                0.500          0.000      0.000  \n",
       "75%                 0.000          0.000               0.000       0.000         0.000          0.047       0.500      0.091                   0.341                   0.015            0.080            0.200           0.100         0.018                1.000          0.111             0.500                0.500          0.000      1.000  \n",
       "max                 1.000          1.000               1.000       1.000         1.000          1.000       1.000      1.000                   1.000                   1.000            1.000            1.000           1.000         1.000                1.000          1.000             1.000                1.000          1.000      1.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of data\n",
    "\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X = data.drop(\"phishing\", axis=1)\n",
    "y = data[\"phishing\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20, stratify=data[\"phishing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy prediction runs multiple classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
       " ('BaggingClassifier', sklearn.ensemble._bagging.BaggingClassifier),\n",
       " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
       " ('CalibratedClassifierCV', sklearn.calibration.CalibratedClassifierCV),\n",
       " ('CategoricalNB', sklearn.naive_bayes.CategoricalNB),\n",
       " ('DecisionTreeClassifier', sklearn.tree._classes.DecisionTreeClassifier),\n",
       " ('DummyClassifier', sklearn.dummy.DummyClassifier),\n",
       " ('ExtraTreeClassifier', sklearn.tree._classes.ExtraTreeClassifier),\n",
       " ('ExtraTreesClassifier', sklearn.ensemble._forest.ExtraTreesClassifier),\n",
       " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
       " ('KNeighborsClassifier',\n",
       "  sklearn.neighbors._classification.KNeighborsClassifier),\n",
       " ('LabelPropagation',\n",
       "  sklearn.semi_supervised._label_propagation.LabelPropagation),\n",
       " ('LabelSpreading', sklearn.semi_supervised._label_propagation.LabelSpreading),\n",
       " ('LinearDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.LinearDiscriminantAnalysis),\n",
       " ('LinearSVC', sklearn.svm._classes.LinearSVC),\n",
       " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
       " ('NearestCentroid', sklearn.neighbors._nearest_centroid.NearestCentroid),\n",
       " ('NuSVC', sklearn.svm._classes.NuSVC),\n",
       " ('PassiveAggressiveClassifier',\n",
       "  sklearn.linear_model._passive_aggressive.PassiveAggressiveClassifier),\n",
       " ('Perceptron', sklearn.linear_model._perceptron.Perceptron),\n",
       " ('QuadraticDiscriminantAnalysis',\n",
       "  sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis),\n",
       " ('RandomForestClassifier', sklearn.ensemble._forest.RandomForestClassifier),\n",
       " ('RidgeClassifier', sklearn.linear_model._ridge.RidgeClassifier),\n",
       " ('RidgeClassifierCV', sklearn.linear_model._ridge.RidgeClassifierCV),\n",
       " ('SGDClassifier', sklearn.linear_model._stochastic_gradient.SGDClassifier),\n",
       " ('SVC', sklearn.svm._classes.SVC),\n",
       " ('StackingClassifier', sklearn.ensemble._stacking.StackingClassifier),\n",
       " ('XGBClassifier', xgboost.sklearn.XGBClassifier),\n",
       " ('LGBMClassifier', lightgbm.sklearn.LGBMClassifier)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all claasifiers in lazy prediction\n",
    "Supervised.CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove problematic/bad performance classifiers from Supervised.CLASSIFIERS\n",
    "Supervised.CLASSIFIERS = [classifier for classifier in Supervised.CLASSIFIERS\n",
    "                          if classifier[1] not in [\n",
    "                              sklearn.svm.NuSVC,\n",
    "                              sklearn.svm.SVC,\n",
    "                              sklearn.svm.LinearSVC,\n",
    "                              sklearn.calibration.CalibratedClassifierCV\n",
    "                          ]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 1/25 [00:12<05:02, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostClassifier', 'Accuracy': 0.9265227447956823, 'Balanced Accuracy': 0.9231239206302253, 'ROC AUC': 0.9231239206302253, 'F1 Score': 0.9264877067301567, 'Time taken': 12.608210563659668}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 2/25 [00:27<05:21, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingClassifier', 'Accuracy': 0.9841557440246723, 'Balanced Accuracy': 0.9831084593438619, 'ROC AUC': 0.9831084593438619, 'F1 Score': 0.9841490798972385, 'Time taken': 14.903014659881592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 3/25 [00:28<02:57,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BernoulliNB', 'Accuracy': 0.8402852737085582, 'Balanced Accuracy': 0.8623674673478425, 'ROC AUC': 0.8623674673478425, 'F1 Score': 0.8415394061669077, 'Time taken': 1.0905580520629883}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 4/25 [00:29<01:49,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB model failed to execute\n",
      "Negative values in data passed to CategoricalNB (input X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 5/25 [00:32<01:29,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeClassifier', 'Accuracy': 0.9798766383962991, 'Balanced Accuracy': 0.9789648829373655, 'ROC AUC': 0.9789648829373655, 'F1 Score': 0.9798744210026621, 'Time taken': 3.248779296875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 6/25 [00:33<01:01,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DummyClassifier', 'Accuracy': 0.5978797224363916, 'Balanced Accuracy': 0.5, 'ROC AUC': 0.5, 'F1 Score': 0.44741810973803947, 'Time taken': 0.7861182689666748}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 7/25 [00:34<00:45,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreeClassifier', 'Accuracy': 0.9761372397841171, 'Balanced Accuracy': 0.9757591929931007, 'ROC AUC': 0.9757591929931005, 'F1 Score': 0.9761506978970071, 'Time taken': 1.053560733795166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 8/25 [00:56<02:26,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesClassifier', 'Accuracy': 0.9874710871241326, 'Balanced Accuracy': 0.9870895347402322, 'ROC AUC': 0.9870895347402323, 'F1 Score': 0.9874725572034386, 'Time taken': 21.61949586868286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 9/25 [00:57<01:40,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianNB', 'Accuracy': 0.7288743253662298, 'Balanced Accuracy': 0.6700366595133089, 'ROC AUC': 0.6700366595133088, 'F1 Score': 0.6949262531145344, 'Time taken': 1.0886623859405518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 10/25 [01:07<01:50,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'KNeighborsClassifier', 'Accuracy': 0.9579799537393986, 'Balanced Accuracy': 0.9563839772180489, 'ROC AUC': 0.9563839772180488, 'F1 Score': 0.957983244189513, 'Time taken': 9.883423089981079}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 11/25 [01:07<01:14,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelPropagation model failed to execute\n",
      "Unable to allocate 80.2 GiB for an array with shape (103758, 103758) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 12/25 [01:08<00:50,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelSpreading model failed to execute\n",
      "Unable to allocate 80.2 GiB for an array with shape (103758, 103758) and data type float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 13/25 [01:10<00:39,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearDiscriminantAnalysis', 'Accuracy': 0.9033924441017733, 'Balanced Accuracy': 0.911203905780408, 'ROC AUC': 0.911203905780408, 'F1 Score': 0.9041737744796897, 'Time taken': 2.030305862426758}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 14/25 [01:12<00:32,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LogisticRegression', 'Accuracy': 0.9223592906707787, 'Balanced Accuracy': 0.9210702888867217, 'ROC AUC': 0.9210702888867217, 'F1 Score': 0.9224926061877424, 'Time taken': 2.0556552410125732}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 15/25 [01:13<00:22,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'NearestCentroid', 'Accuracy': 0.8402852737085582, 'Balanced Accuracy': 0.8623674673478425, 'ROC AUC': 0.8623674673478425, 'F1 Score': 0.8415394061669077, 'Time taken': 0.7500252723693848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 16/25 [01:14<00:17,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressiveClassifier', 'Accuracy': 0.905242868157286, 'Balanced Accuracy': 0.9064892098890394, 'ROC AUC': 0.9064892098890394, 'F1 Score': 0.9056549098317407, 'Time taken': 1.0529649257659912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 17/25 [01:15<00:13,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Perceptron', 'Accuracy': 0.8913646877409407, 'Balanced Accuracy': 0.8814169949618537, 'ROC AUC': 0.8814169949618537, 'F1 Score': 0.8906597530503608, 'Time taken': 1.0602195262908936}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 18/25 [01:17<00:12,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'QuadraticDiscriminantAnalysis', 'Accuracy': 0.7042020046260601, 'Balanced Accuracy': 0.6336930862210264, 'ROC AUC': 0.6336930862210264, 'F1 Score': 0.650226150453162, 'Time taken': 1.9102988243103027}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 19/25 [01:36<00:41,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestClassifier', 'Accuracy': 0.9883191981495759, 'Balanced Accuracy': 0.9878458844215374, 'ROC AUC': 0.9878458844215375, 'F1 Score': 0.9883191064667579, 'Time taken': 19.00005602836609}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 20/25 [01:37<00:25,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RidgeClassifier', 'Accuracy': 0.9037008481110255, 'Balanced Accuracy': 0.9114304311438587, 'ROC AUC': 0.9114304311438587, 'F1 Score': 0.9044760771502401, 'Time taken': 1.1350808143615723}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 21/25 [01:39<00:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RidgeClassifierCV', 'Accuracy': 0.9035851966075559, 'Balanced Accuracy': 0.9113337131091692, 'ROC AUC': 0.9113337131091691, 'F1 Score': 0.9043622635179099, 'Time taken': 2.4391069412231445}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 22/25 [01:42<00:11,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SGDClassifier', 'Accuracy': 0.9158057054741712, 'Balanced Accuracy': 0.9185558981499784, 'ROC AUC': 0.9185558981499785, 'F1 Score': 0.9162361247094858, 'Time taken': 2.3082172870635986}\n",
      "StackingClassifier model failed to execute\n",
      "StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 24/25 [01:43<00:02,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBClassifier', 'Accuracy': 0.9710871241326138, 'Balanced Accuracy': 0.9697152538598217, 'ROC AUC': 0.9697152538598217, 'F1 Score': 0.9710807333827347, 'Time taken': 1.450500726699829}\n",
      "[LightGBM] [Info] Number of positive: 41721, number of negative: 62037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3191\n",
      "[LightGBM] [Info] Number of data points in the train set: 103758, number of used features: 96\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402099 -> initscore=-0.396726\n",
      "[LightGBM] [Info] Start training from score -0.396726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25/25 [01:45<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMClassifier', 'Accuracy': 0.9633770239013107, 'Balanced Accuracy': 0.962058893145249, 'ROC AUC': 0.962058893145249, 'F1 Score': 0.9633821771899386, 'Time taken': 1.7352268695831299}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lazy prediction\n",
    "clf = LazyClassifier(verbose=1, ignore_warnings=False, custom_metric=None, predictions=True, classifiers=\"all\" ) # verbose set as 1 to monitor progress\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>19.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>21.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.984</td>\n",
       "      <td>14.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.980</td>\n",
       "      <td>3.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.971</td>\n",
       "      <td>1.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.958</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.958</td>\n",
       "      <td>9.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.926</td>\n",
       "      <td>12.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.922</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.922</td>\n",
       "      <td>2.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.904</td>\n",
       "      <td>2.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.904</td>\n",
       "      <td>2.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.906</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.842</td>\n",
       "      <td>1.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.695</td>\n",
       "      <td>1.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.598</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  Time Taken\n",
       "Model                                                                                    \n",
       "RandomForestClassifier            0.988              0.988    0.988     0.988      19.000\n",
       "ExtraTreesClassifier              0.987              0.987    0.987     0.987      21.619\n",
       "BaggingClassifier                 0.984              0.983    0.983     0.984      14.903\n",
       "DecisionTreeClassifier            0.980              0.979    0.979     0.980       3.249\n",
       "ExtraTreeClassifier               0.976              0.976    0.976     0.976       1.054\n",
       "XGBClassifier                     0.971              0.970    0.970     0.971       1.451\n",
       "LGBMClassifier                    0.963              0.962    0.962     0.963       1.735\n",
       "KNeighborsClassifier              0.958              0.956    0.956     0.958       9.883\n",
       "AdaBoostClassifier                0.927              0.923    0.923     0.926      12.608\n",
       "LogisticRegression                0.922              0.921    0.921     0.922       2.056\n",
       "SGDClassifier                     0.916              0.919    0.919     0.916       2.308\n",
       "RidgeClassifier                   0.904              0.911    0.911     0.904       1.135\n",
       "RidgeClassifierCV                 0.904              0.911    0.911     0.904       2.439\n",
       "LinearDiscriminantAnalysis        0.903              0.911    0.911     0.904       2.030\n",
       "PassiveAggressiveClassifier       0.905              0.906    0.906     0.906       1.053\n",
       "Perceptron                        0.891              0.881    0.881     0.891       1.060\n",
       "NearestCentroid                   0.840              0.862    0.862     0.842       0.750\n",
       "BernoulliNB                       0.840              0.862    0.862     0.842       1.091\n",
       "GaussianNB                        0.729              0.670    0.670     0.695       1.089\n",
       "QuadraticDiscriminantAnalysis     0.704              0.634    0.634     0.650       1.910\n",
       "DummyClassifier                   0.598              0.500    0.500     0.447       0.786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through lazy prediction, the best performing models are **RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, DecisionTreeClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9879336931380108\n",
      "Recall: 0.9849487105742498\n"
     ]
    }
   ],
   "source": [
    "# Rf Classifier\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment if replacing -1 helps the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9882035466461064\n",
      "Recall: 0.9849487105742498\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame 'cleaned_df' with -1 replaced by mean\n",
    "cleaned_data = data.copy()  # Make a copy of the original DataFrame\n",
    "\n",
    "# Replace -1 with the mean of each column\n",
    "for col in cleaned_data .columns[:-1]:\n",
    "    if -1 in cleaned_data[col].values:\n",
    "        mean_val = cleaned_data [col][cleaned_data[col] != -1].mean()\n",
    "        cleaned_data[col] = cleaned_data[col].replace(to_replace=-1, value=mean_val)\n",
    "\n",
    "# Train test split\n",
    "clean_X = cleaned_data.drop(\"phishing\", axis=1)\n",
    "clean_y = cleaned_data[\"phishing\"]\n",
    "clean_X_train, clean_X_test, clean_y_train, clean_y_test = train_test_split(clean_X, clean_y, test_size=0.2, random_state=20, stratify=cleaned_data[\"phishing\"])\n",
    "\n",
    "# Rf Classifier\n",
    "clean_clf = RandomForestClassifier().fit(clean_X_train, clean_y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "clean_y_pred = clean_clf.predict(clean_X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(clean_y_test, clean_y_pred)\n",
    "recall = recall_score(clean_y_test, clean_y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  47\n",
      "min_depth:  32\n",
      "max_depth:  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "print(\"max_depth: \", max((e.tree_.max_depth for e in clf.estimators_)))\n",
    "print(\"min_depth: \", min((e.tree_.max_depth for e in clf.estimators_)))\n",
    "print(\"max_depth: \", clf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !! CAUTION: This cell takes long time to run !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m      9\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m],\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m70\u001b[39m],\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m],\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(clean_clf, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m     20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\16604\\Desktop\\Y4S2\\DSA4263\\Project\\dsa4263-fraud-detection\\dsa4263venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "# param_grid = {\n",
    "#     \"estimator\": [DecisionTreeClassifier(), ExtraTreesClassifier(), RandomForestClassifier()],\n",
    "#     \"base_estimator__max_depth\" : [1, 2, 3, 4, 5],\n",
    "#     \"max_samples\" : [0.05, 0.1, 0.2, 0.5]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [30, 50, 70],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "model = RandomizedSearchCV(clean_clf, param_grid, cv=5, n_iter=20, verbose=1)\n",
    "model.fit(clean_X_train, clean_y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = model.best_params_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(clean_X_test)\n",
    " \n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(clean_y_test, y_pred)\n",
    "recall = recall_score(clean_y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance of initial model\n",
    "\n",
    "# feature_importance = clf.feature_importances_\n",
    "feature_importances = np.mean([\n",
    "    tree.feature_importances_ for tree in clf.estimators_\n",
    "], axis=0)\n",
    "sorted_idx = np.argsort(feature_importances)[-20:]\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align=\"center\")\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance of Classification of Initial Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance of tuned model\n",
    "\n",
    "# feature_importance = model.feature_importances_\n",
    "feature_importances = np.mean([\n",
    "    tree.feature_importances_ for tree in model.best_estimator_\n",
    "], axis=0)\n",
    "sorted_idx = np.argsort(feature_importances)[-20:]\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), feature_importances[sorted_idx], align=\"center\")\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance of Classification of Tuned Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree as dot file\n",
    "\n",
    "# for i in range(len(model.best_estimator_)):\n",
    "#     export_graphviz(model.best_estimator_[i], out_file=f\"visualization/tree_{i}.dot\", \n",
    "#                 feature_names=cleaned_data.drop(\"phishing\", axis=1).columns,\n",
    "#                 class_names=[\"phishing\"],\n",
    "#                 filled=True,\n",
    "#                 rounded=True, proportion=False, \n",
    "#                 precision=2, filled=True)\n",
    "\n",
    "#     # Convert to png using system command (requires Graphviz)\n",
    "#     # os.system('dot -Tpng tree.dot -o tree.png')\n",
    "#     call([\"dot\", \"-Tpng\", f\"tree_{i}.dot\", \"-o\", f\"tree_{i}.png\", \"-Gdpi=300\"])\n",
    "\n",
    "#     # Display in jupyter notebook\n",
    "#     Image(filename = f\"tree_{i}.png\")\n",
    "\n",
    "# Alternatively\n",
    "# for i in range(len(model.best_estimator_)):\n",
    "#     fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4,4), dpi=300)\n",
    "#     tree.plot_tree(model.best_estimator_[i],\n",
    "#                 feature_names=list(cleaned_data.columns.drop(\"phishing\")), \n",
    "#                 class_names=[\"phishing\"],\n",
    "#                 filled=True, \n",
    "#                 rounded=True, proportion=False, \n",
    "#                 precision=2)\n",
    "    \n",
    "#     fig.savefig(f\"visualization/tree_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.discovery import all_displays\n",
    "\n",
    "displays = all_displays()\n",
    "displays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(clean_y_test, y_pred)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "precision, recall, _ = precision_recall_curve(clean_y_test, y_pred)\n",
    "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(clean_y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=\"RandomForest\")\n",
    "display.plot(color='black', linestyle='-')\n",
    "# plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.plot([0, 0], [0, 1], color='red', linestyle='-.')\n",
    "plt.plot([0, 1], [1, 1], color='red', linestyle='-.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfectly calibrated model would have a calibration curve closely aligned with the 45-degree diagonal line on the plot. This line represents ideal calibration, where the **predicted probabilities match the observed frequencies**. Deviations from this diagonal line indicate either overconfidence or underconfidence in the model's predictions.\n",
    "\n",
    "- Overconfidence: If the curve lies above the diagonal line, the model is overconfident. This means there are more instances with predicted probabilities close to 1 than there should be, and the model's confidence in its predictions is higher than the actual success rate.\n",
    "- Underconfidence: If the curve lies below the diagonal line, the model is underconfident. In this case, instances with high predicted probabilities are less frequent than they should be and the model's confidence is lower than the actual success rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibrationDisplay\n",
    "CalibrationDisplay.from_estimator(model, clean_X_test, clean_y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Reconstruct best model\n",
    "n_estimators = best_params[\"n_estimators\"]\n",
    "min_samples_split = best_params[\"min_samples_split\"]\n",
    "max_features = best_params[\"max_features\"]\n",
    "max_depth = best_params[\"max_depth\"]\n",
    "tree = RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split, max_features=max_features, max_depth=max_depth)\n",
    "\n",
    "tree = tree.fit(clean_X_train[clean_X_train.columns[sorted_idx[-2:]]], clean_y_train)\n",
    "display = DecisionBoundaryDisplay.from_estimator(\n",
    "    tree, clean_X_train[clean_X_train.columns[sorted_idx[-2:]]], response_method=\"predict\",\n",
    "    xlabel=clean_X_train.columns[sorted_idx[-1]], ylabel=clean_X_train.columns[sorted_idx[-2]],\n",
    "    alpha=0.5,\n",
    ")\n",
    "clean_df = pd.concat([clean_X_train, clean_y_train], axis=1)\n",
    "samples = clean_df.sample(frac=0.001, replace=False, random_state=1)\n",
    "display.ax_.scatter(clean_X_train[clean_X_train.columns[sorted_idx[-1]]], clean_X_train[clean_X_train.columns[sorted_idx[-2]]], c=clean_y_train, edgecolor=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(clf, clean_X_train, clean_y_train)\n",
    "display = LearningCurveDisplay(train_sizes=train_sizes, train_scores=train_scores, test_scores=test_scores, score_name=\"Score\")\n",
    "display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
